{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b7ee8",
   "metadata": {
    "id": "8b9b7ee8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense      #neural net layer\n",
    "import pandas as pd                  \n",
    "from sklearn.model_selection import train_test_split   #to spit dataset into train,validation,test \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "\n",
    "def mse(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.square(np.subtract(actual,pred)).mean()                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/USER/Desktop/TheGoldenTrio/DCMD_transport_model')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f0286",
   "metadata": {
    "id": "545f0286"
   },
   "outputs": [],
   "source": [
    "#Store the dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\USER\\Desktop\\TheGoldenTrio\\new_topsis.xlsx\")\n",
    "\n",
    "dataset = df.values                          #Convert the data into an array\n",
    "inputs  = dataset[2:279,0:4]                #end - 1  \n",
    "targets = dataset[2:279,4:5]               #end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170cc77",
   "metadata": {
    "id": "9170cc77"
   },
   "outputs": [],
   "source": [
    "#How to split this into train & test data?\n",
    "X_train, x_test, Y_train, y_test = train_test_split(inputs, targets, test_size=0.2, random_state = 4)   \n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcb988",
   "metadata": {
    "id": "6ebcb988"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.fit_transform(x_test)\n",
    "Y_train = sc.fit_transform(y_train)\n",
    "Y_test = sc.fit_transform(y_test)\n",
    "INPUTS = sc.fit_transform(inputs)\n",
    "TARGETS = sc.fit_transform(targets)\n",
    "X_val = sc.fit_transform(x_val)\n",
    "Y_val = sc.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b801b01",
   "metadata": {
    "id": "8b801b01"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2bc9a",
   "metadata": {
    "id": "00e2bc9a",
    "outputId": "781e8c92-ab08-4ba5-e62a-690b4d220f44"
   },
   "outputs": [],
   "source": [
    "HP_1 = hp.HParam('num_units1', hp.Discrete([8,16,24,32,36,48,54,60,72,76,80,84,88,94,96])) #\n",
    "HP_2 = hp.HParam('num_units2', hp.Discrete([8,16,24,32,36,48,54,60])) #4,8,12,16,20,24,32,36,\n",
    "HP_3 = hp.HParam('num_units3', hp.Discrete([4,8,16,20])) #2,4,6,8,\n",
    "HP_ACTIVATION_1 = hp.HParam('act_1', hp.Discrete(['relu','sigmoid','tanh'])) #\n",
    "HP_ACTIVATION_2 = hp.HParam('act_2', hp.Discrete(['relu','sigmoid','tanh'])) #\n",
    "HP_ACTIVATION_3 = hp.HParam('act_3', hp.Discrete(['relu','tanh'])) #\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['Adam'])) #,'RMSprop','Adagrad','Adamax'\n",
    "\n",
    "'''\n",
    "MSE = 'mse'\n",
    "R2_all = 'R2_all'\n",
    "R2_train = 'R2_train'\n",
    "R2_test = 'R2_test'\n",
    "R2_val = 'R2_val'\n",
    "#logdir = 'C:/Users/USER/Desktop/TheGoldenTrio/DCMD_transport_model/logs/hparam_tuning'\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_1, HP_ACTIVATION_1, HP_2, HP_ACTIVATION_2, HP_3, HP_ACTIVATION_3, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(MSE, display_name='MSE'),hp.Metric(R2_all, display_name='R2_all'),hp.Metric(R2_train, display_name='R2_train') \n",
    "            ,hp.Metric(R2_test, display_name='R2_test'),hp.Metric(R2_val, display_name='R2_val')], \n",
    "  )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42db432",
   "metadata": {
    "id": "c42db432"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#log_folder = 'C:/Users/USER/Desktop/TheGoldenTrio/DCMD_transport_model/logs/'\n",
    "#tb_callback = TensorBoard(log_dir=log_folder)\n",
    "\n",
    "def train_test_model(hparams):\n",
    "  model = tf.keras.models.Sequential([\n",
    "    Input(shape=(4, )), \n",
    "    Dense(hparams[HP_1], activation=hparams[HP_ACTIVATION_1]),\n",
    "    Dense(hparams[HP_2], activation=hparams[HP_ACTIVATION_2]), \n",
    "    Dense(hparams[HP_3], activation=hparams[HP_ACTIVATION_3]),  \n",
    "    Dense(1, )\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='mse',\n",
    "      metrics=['mae'],\n",
    "  )\n",
    "\n",
    "  model.fit(X_train, Y_train, epochs=100, validation_data = (X_val,Y_val),batch_size=2) #, callbacks=[tb_callback]\n",
    "\n",
    "  y_pred = model.predict(INPUTS)\n",
    "  y_pred_inv = sc.inverse_transform(y_pred)\n",
    "\n",
    "  y_predtrain = model.predict(X_train)\n",
    "  y_predtrain_inv = sc.inverse_transform(y_predtrain)\n",
    "\n",
    "  y_predval = model.predict(X_val)\n",
    "  y_predval_inv = sc.inverse_transform(y_predval)\n",
    "\n",
    "  y_predtest = model.predict(X_test)\n",
    "  y_predtest_inv = sc.inverse_transform(y_predtest)\n",
    "  print(model.summary())\n",
    "\n",
    "  r2_all = r2_score(targets, y_pred_inv)\n",
    "  r2_test = r2_score(y_test, y_predtest_inv)\n",
    "  r2_train = r2_score(y_train, y_predtrain_inv)\n",
    "  r2_val = r2_score(y_val, y_predval_inv)\n",
    "  print('r2_all:', r2_all)\n",
    "  print('r2_train:', r2_train)\n",
    "  print('r2_test:', r2_test)\n",
    "  print('r2_val:', r2_val)\n",
    "  accuracy = [0,0,0,0,0]\n",
    "  accuracy[0] = mse(targets, y_pred_inv)\n",
    "  accuracy[1] = r2_all\n",
    "  accuracy[2] = r2_train\n",
    "  accuracy[3] = r2_test\n",
    "  accuracy[4] = r2_val\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea0c3a",
   "metadata": {
    "id": "ceea0c3a"
   },
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  acc = train_test_model(hparams)\n",
    "  \n",
    "  #keys_hp = hparams.keys()\n",
    "\n",
    "  return acc\n",
    "  \n",
    "  '''with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = acc[0]\n",
    "    R2_all = acc[1] \n",
    "    R2_train = acc[2]\n",
    "    R2_test = acc[3]\n",
    "    R2_val = acc[4]\n",
    "    tf.summary.scalar('loss', accuracy, step=1)\n",
    "    tf.summary.scalar('R2_all',R2_all, step=2)\n",
    "    tf.summary.scalar('R2_train',R2_train, step=3)\n",
    "    tf.summary.scalar('R2_test',R2_test, step=4)\n",
    "    tf.summary.scalar('R2_val',R2_val, step=5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf1bac",
   "metadata": {
    "id": "14bf1bac"
   },
   "outputs": [],
   "source": [
    "#import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ceb9d5",
   "metadata": {
    "id": "60ceb9d5"
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "keys = ['loss', 'R2_all','R2_train','R2_test','R2_val']\n",
    " \n",
    "data = []\n",
    "for num_units1 in HP_1.domain.values:\n",
    "    for act_1 in HP_ACTIVATION_1.domain.values:\n",
    "        for num_units2 in HP_2.domain.values:\n",
    "            for act_2 in HP_ACTIVATION_2.domain.values:\n",
    "                for num_units3 in HP_3.domain.values:\n",
    "                    for act_3 in HP_ACTIVATION_3.domain.values:\n",
    "                        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                            hparams = {\n",
    "                              HP_1: num_units1,\n",
    "                              HP_ACTIVATION_1: act_1,\n",
    "                              HP_2: num_units2,\n",
    "                              HP_ACTIVATION_2: act_2,\n",
    "                              HP_3: num_units3,\n",
    "                              HP_ACTIVATION_3: act_3, \n",
    "                              HP_OPTIMIZER: optimizer  \n",
    "                            }\n",
    "                            run_name = \"run-%d\" % session_num\n",
    "                            print('--- Starting trial: %s' % run_name)\n",
    "                            print({h.name: hparams[h] for h in hparams})\n",
    "                            acc = run('C:/Users/USER/Desktop/TheGoldenTrio/DCMD_transport_model/logs/hparam_tuning/' + run_name, hparams)\n",
    "                            tf.keras.backend.clear_session()\n",
    "                            dict = {}\n",
    "                            for (i,j) in zip(keys, acc):\n",
    "                                dict[i] = j\n",
    "                            for i in hparams.keys():\n",
    "                                dict[i] = hparams[i]\n",
    "                            data.append(dict)\n",
    "                            session_num += 1\n",
    "data = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1521f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"Adam.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fd766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0b935",
   "metadata": {
    "id": "e8c0b935"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir C:/Users/USER/Desktop/TheGoldenTrio/DCMD_transport_model/logs/hparam_tuning\n",
    "#%tensorboard --logdir logs/hparam_tuning '''"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "ANN_tensorboard.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
